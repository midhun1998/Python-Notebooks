{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:100, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = iris.target[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:10]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0 here is Iris Setosa and 1 here is Iris Virginica\n",
    "\n",
    "- Now the data X_norm is of shape (100,4)\n",
    "\n",
    "- But for SNN we need to have the data of shape (no_of_features x no_of_samples). So take a transpose of X_norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X.T\n",
    "Y_data = Y.reshape(1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 100)\n",
      "(1, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X_data.shape)\n",
    "print(Y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before we start the forward propagation, we need to initialize weights and bias to some random values.\n",
    "\n",
    "- Since we have four features, we need to have weight vector of shape (4,1) and one bias term of shape (1,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeNetwork(num_features):\n",
    "    w = np.zeros((num_features, 1))\n",
    "    b = 0\n",
    "    param = {\"W\":w, \"b\":b}\n",
    "    return param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before going with the forward propagation, we need to define an activation function for the neuron.\n",
    "\n",
    "- Since this is a binary classification, let's consider a sigmoid function that maps any linear input to values between 0 to 1.\n",
    "\n",
    "- The sigmoid activation function is implemented as shown in the below code snippet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You have seen the theoretical implementation of forward propagation in the previous topic.\n",
    "\n",
    "- The same is implemented and Calculating cost function for a given number of samples is as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPropagation(x, y, param):\n",
    "    w = param[\"W\"]\n",
    "    b = param[\"b\"]\n",
    "    z = np.dot(w.T, x) + b\n",
    "    a = sigmoid(z)\n",
    "    return a\n",
    "\n",
    "def cost(a, y, num_samples):\n",
    "    return -1/num_samples*np.sum(y*np.log(a)) + (1-y)*(np.log(1-a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From forward propagation, you know the output A.\n",
    "\n",
    "- Using this output, you need to find the derivatives of weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backPropagation(x, y, a, n):\n",
    "    dz = a - y\n",
    "    dw = (np.dot(x,dz.T))/n\n",
    "    db = np.sum(dz)/n\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once we have the derivatives, you need to subtract them from original weights and bias.\n",
    "\n",
    "- While subtracting, we multiply the derivatives with a learning rate to have control over the gradient at each step of iteration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParam(param, dw, db, lr):\n",
    "    w = param[\"W\"] - (lr * dw)\n",
    "    b = param[\"b\"] - (lr * db)\n",
    "    return {\"W\":w, \"b\":b}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's define the model to initialize and train the SNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, y, num_iter, lr):\n",
    "    num_features = x.shape[0]\n",
    "    num_samples = float(x.shape[1])\n",
    "    param = initializeNetwork(num_features)\n",
    "    for i in range(num_iter):\n",
    "        a = forwardPropagation(x, y, param)\n",
    "        if(i%100 == 0):\n",
    "            print('cost after {} iteration: {}'.format(i, cost(a, y, num_samples)))\n",
    "        dw, db = backPropagation(x, y, a, num_samples)\n",
    "        param = updateParam(param, dw, db, lr)\n",
    "    return param\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using iris dataset with learning rate 0.1 and number of iteration equal to 1000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 0 iteration: [[-0.34657359 -0.34657359 -0.34657359 -0.34657359 -0.34657359 -0.34657359\n",
      "  -0.34657359 -0.34657359 -0.34657359 -0.34657359 -0.34657359 -0.34657359\n",
      "  -0.34657359 -0.34657359 -0.34657359 -0.34657359 -0.34657359 -0.34657359\n",
      "  -0.34657359 -0.34657359 -0.34657359 -0.34657359 -0.34657359 -0.34657359\n",
      "  -0.34657359 -0.34657359 -0.34657359 -0.34657359 -0.34657359 -0.34657359\n",
      "  -0.34657359 -0.34657359 -0.34657359 -0.34657359 -0.34657359 -0.34657359\n",
      "  -0.34657359 -0.34657359 -0.34657359 -0.34657359 -0.34657359 -0.34657359\n",
      "  -0.34657359 -0.34657359 -0.34657359 -0.34657359 -0.34657359 -0.34657359\n",
      "  -0.34657359 -0.34657359  0.34657359  0.34657359  0.34657359  0.34657359\n",
      "   0.34657359  0.34657359  0.34657359  0.34657359  0.34657359  0.34657359\n",
      "   0.34657359  0.34657359  0.34657359  0.34657359  0.34657359  0.34657359\n",
      "   0.34657359  0.34657359  0.34657359  0.34657359  0.34657359  0.34657359\n",
      "   0.34657359  0.34657359  0.34657359  0.34657359  0.34657359  0.34657359\n",
      "   0.34657359  0.34657359  0.34657359  0.34657359  0.34657359  0.34657359\n",
      "   0.34657359  0.34657359  0.34657359  0.34657359  0.34657359  0.34657359\n",
      "   0.34657359  0.34657359  0.34657359  0.34657359  0.34657359  0.34657359\n",
      "   0.34657359  0.34657359  0.34657359  0.34657359]]\n",
      "cost after 100 iteration: [[-2.37186933e-02 -6.37989531e-02 -3.94622354e-02 -7.70447164e-02\n",
      "  -1.98661670e-02 -2.99709370e-02 -4.26632327e-02 -4.12558838e-02\n",
      "  -8.82623955e-02 -6.26199438e-02 -1.72003774e-02 -5.76390097e-02\n",
      "  -6.02460396e-02 -3.51204849e-02  1.04395972e-02  5.64401578e-03\n",
      "  -2.22805547e-03 -2.73977317e-02 -2.72761056e-02 -1.94290621e-02\n",
      "  -5.69886656e-02 -2.84549062e-02  1.51417082e-04 -9.63644826e-02\n",
      "  -1.07941718e-01 -9.36556132e-02 -6.46782665e-02 -3.10322497e-02\n",
      "  -2.78630023e-02 -7.98389190e-02 -8.80995517e-02 -4.29955388e-02\n",
      "  -1.02496050e-03  6.37699005e-03 -6.88563018e-02 -2.48938931e-02\n",
      "  -1.12674920e-02 -1.79455525e-02 -6.20138487e-02 -3.93645254e-02\n",
      "  -2.05119857e-02 -1.59676657e-01 -4.52956071e-02 -6.76199673e-02\n",
      "  -6.76829316e-02 -7.28040795e-02 -2.40108897e-02 -5.31927438e-02\n",
      "  -1.84980372e-02 -3.75695843e-02  2.95557733e-02  2.95557733e-02\n",
      "   2.95557733e-02  2.95557733e-02  2.95557733e-02  2.95557733e-02\n",
      "   2.95557733e-02  2.95557733e-02  2.95557733e-02  2.95557733e-02\n",
      "   2.95557733e-02  2.95557733e-02  2.95557733e-02  2.95557733e-02\n",
      "   2.95557733e-02  2.95557733e-02  2.95557733e-02  2.95557733e-02\n",
      "   2.95557733e-02  2.95557733e-02  2.95557733e-02  2.95557733e-02\n",
      "   2.95557733e-02  2.95557733e-02  2.95557733e-02  2.95557733e-02\n",
      "   2.95557733e-02  2.95557733e-02  2.95557733e-02  2.95557733e-02\n",
      "   2.95557733e-02  2.95557733e-02  2.95557733e-02  2.95557733e-02\n",
      "   2.95557733e-02  2.95557733e-02  2.95557733e-02  2.95557733e-02\n",
      "   2.95557733e-02  2.95557733e-02  2.95557733e-02  2.95557733e-02\n",
      "   2.95557733e-02  2.95557733e-02  2.95557733e-02  2.95557733e-02\n",
      "   2.95557733e-02  2.95557733e-02  2.95557733e-02  2.95557733e-02]]\n",
      "cost after 200 iteration: [[-0.00869585 -0.03456918 -0.01837541 -0.04403774 -0.00646594 -0.01241046\n",
      "  -0.02044551 -0.01947067 -0.05237252 -0.03371798 -0.00491498 -0.03032192\n",
      "  -0.03210409 -0.01568287  0.00909117  0.0069239   0.00308678 -0.01089008\n",
      "  -0.01074821 -0.00621359 -0.02977869 -0.01153255  0.00424799 -0.05839855\n",
      "  -0.06731547 -0.05627507 -0.03519211 -0.01306003 -0.01114784 -0.04604284\n",
      "  -0.05213469 -0.02057162  0.00370399  0.00726355 -0.0381098  -0.00940628\n",
      "  -0.0016324  -0.00536651 -0.03342132 -0.01825448 -0.00685232 -0.11051553\n",
      "  -0.02216729 -0.03730468 -0.03725327 -0.04097601 -0.00885812 -0.02735967\n",
      "  -0.00565741 -0.0171381   0.01562568  0.01562568  0.01562568  0.01562568\n",
      "   0.01562568  0.01562568  0.01562568  0.01562568  0.01562568  0.01562568\n",
      "   0.01562568  0.01562568  0.01562568  0.01562568  0.01562568  0.01562568\n",
      "   0.01562568  0.01562568  0.01562568  0.01562568  0.01562568  0.01562568\n",
      "   0.01562568  0.01562568  0.01562568  0.01562568  0.01562568  0.01562568\n",
      "   0.01562568  0.01562568  0.01562568  0.01562568  0.01562568  0.01562568\n",
      "   0.01562568  0.01562568  0.01562568  0.01562568  0.01562568  0.01562568\n",
      "   0.01562568  0.01562568  0.01562568  0.01562568  0.01562568  0.01562568\n",
      "   0.01562568  0.01562568  0.01562568  0.01562568]]\n",
      "cost after 300 iteration: [[-0.00450292 -0.02390143 -0.01154313 -0.03142422 -0.00293384 -0.00716911\n",
      "  -0.01309819 -0.0123486  -0.03818874 -0.02322267 -0.00184669 -0.02060039\n",
      "  -0.02196982 -0.00955868  0.00729135  0.00596918  0.00352901 -0.00607424\n",
      "  -0.00595918 -0.00276081 -0.02015612 -0.0065427   0.00427696 -0.04315897\n",
      "  -0.05055568 -0.04135169 -0.0244121  -0.00762996 -0.00625042 -0.03303125\n",
      "  -0.03796888 -0.01317659  0.00393491  0.00618138 -0.02668687 -0.00500964\n",
      "   0.0004037  -0.00216353 -0.02302641 -0.01144165 -0.00321005 -0.08815921\n",
      "  -0.01438811 -0.02610318 -0.02602936 -0.02898124 -0.00461802 -0.01832731\n",
      "  -0.00236406 -0.01061864  0.01074866  0.01074866  0.01074866  0.01074866\n",
      "   0.01074866  0.01074866  0.01074866  0.01074866  0.01074866  0.01074866\n",
      "   0.01074866  0.01074866  0.01074866  0.01074866  0.01074866  0.01074866\n",
      "   0.01074866  0.01074866  0.01074866  0.01074866  0.01074866  0.01074866\n",
      "   0.01074866  0.01074866  0.01074866  0.01074866  0.01074866  0.01074866\n",
      "   0.01074866  0.01074866  0.01074866  0.01074866  0.01074866  0.01074866\n",
      "   0.01074866  0.01074866  0.01074866  0.01074866  0.01074866  0.01074866\n",
      "   0.01074866  0.01074866  0.01074866  0.01074866  0.01074866  0.01074866\n",
      "   0.01074866  0.01074866  0.01074866  0.01074866]]\n",
      "cost after 400 iteration: [[-0.0026797  -0.0183311  -0.00823558 -0.0246507  -0.00146937 -0.00476848\n",
      "  -0.00949223 -0.00887909 -0.03041718 -0.01775958 -0.00063467 -0.01560151\n",
      "  -0.0167224  -0.00665105  0.00605289  0.00513061  0.00337882 -0.00390704\n",
      "  -0.00381322 -0.00133938 -0.01522608 -0.00427845  0.00392258 -0.03472304\n",
      "  -0.04112732 -0.03312203 -0.01877409 -0.0051232  -0.00403986 -0.0260116\n",
      "  -0.03022057 -0.00955158  0.0036776   0.00528156 -0.02065633 -0.00307301\n",
      "   0.00106964 -0.00087656 -0.01761272 -0.00815083 -0.00168469 -0.07482819\n",
      "  -0.01052957 -0.02020473 -0.02012545 -0.02259342 -0.00276984 -0.0137349\n",
      "  -0.00103069 -0.00749383  0.008248    0.008248    0.008248    0.008248\n",
      "   0.008248    0.008248    0.008248    0.008248    0.008248    0.008248\n",
      "   0.008248    0.008248    0.008248    0.008248    0.008248    0.008248\n",
      "   0.008248    0.008248    0.008248    0.008248    0.008248    0.008248\n",
      "   0.008248    0.008248    0.008248    0.008248    0.008248    0.008248\n",
      "   0.008248    0.008248    0.008248    0.008248    0.008248    0.008248\n",
      "   0.008248    0.008248    0.008248    0.008248    0.008248    0.008248\n",
      "   0.008248    0.008248    0.008248    0.008248    0.008248    0.008248\n",
      "   0.008248    0.008248    0.008248    0.008248  ]]\n",
      "cost after 500 iteration: [[-1.70804234e-03 -1.48945036e-02 -6.30777470e-03 -2.03859217e-02\n",
      "  -7.23316684e-04 -3.42929335e-03 -7.36789609e-03 -6.84669901e-03\n",
      "  -2.54528356e-02 -1.43970153e-02 -4.71931325e-05 -1.25517908e-02\n",
      "  -1.35052281e-02 -4.98260319e-03  5.17916240e-03  4.48491494e-03\n",
      "   3.13693344e-03 -2.71644973e-03 -2.63812058e-03 -6.20128496e-04\n",
      "  -1.22259591e-02 -3.02545852e-03  3.56011899e-03 -2.92922284e-02\n",
      "  -3.49878920e-02 -2.78397582e-02 -1.52907287e-02 -3.71623366e-03\n",
      "  -2.82241845e-03 -2.15768269e-02 -2.52765527e-02 -7.41734207e-03\n",
      "   3.37148172e-03  4.60043390e-03 -1.69057715e-02 -2.02910194e-03\n",
      "   1.31994301e-03 -2.41709089e-04 -1.42795498e-02 -6.23571112e-03\n",
      "  -8.99904017e-04 -6.57775637e-02 -8.23848644e-03 -1.65418084e-02\n",
      "  -1.64620578e-02 -1.85953792e-02 -1.78256692e-03 -1.09567569e-02\n",
      "  -3.67372617e-04 -5.68644037e-03  6.72028784e-03  6.72028784e-03\n",
      "   6.72028784e-03  6.72028784e-03  6.72028784e-03  6.72028784e-03\n",
      "   6.72028784e-03  6.72028784e-03  6.72028784e-03  6.72028784e-03\n",
      "   6.72028784e-03  6.72028784e-03  6.72028784e-03  6.72028784e-03\n",
      "   6.72028784e-03  6.72028784e-03  6.72028784e-03  6.72028784e-03\n",
      "   6.72028784e-03  6.72028784e-03  6.72028784e-03  6.72028784e-03\n",
      "   6.72028784e-03  6.72028784e-03  6.72028784e-03  6.72028784e-03\n",
      "   6.72028784e-03  6.72028784e-03  6.72028784e-03  6.72028784e-03\n",
      "   6.72028784e-03  6.72028784e-03  6.72028784e-03  6.72028784e-03\n",
      "   6.72028784e-03  6.72028784e-03  6.72028784e-03  6.72028784e-03\n",
      "   6.72028784e-03  6.72028784e-03  6.72028784e-03  6.72028784e-03\n",
      "   6.72028784e-03  6.72028784e-03  6.72028784e-03  6.72028784e-03\n",
      "   6.72028784e-03  6.72028784e-03  6.72028784e-03  6.72028784e-03]]\n",
      "cost after 600 iteration: [[-1.12525573e-03 -1.25566540e-02 -5.05544129e-03 -1.74377913e-02\n",
      "  -2.95656279e-04 -2.59117321e-03 -5.97548954e-03 -5.52076262e-03\n",
      "  -2.19821755e-02 -1.21138195e-02  2.71659426e-04 -1.04954082e-02\n",
      "  -1.13276299e-02 -3.91313635e-03  4.53366958e-03  3.98472002e-03\n",
      "   2.89968555e-03 -1.98169853e-03 -1.91489220e-03 -2.10672735e-04\n",
      "  -1.02069351e-02 -2.24700045e-03  3.24378079e-03 -2.54713165e-02\n",
      "  -3.06301890e-02 -2.41325751e-02 -1.29179938e-02 -2.83116544e-03\n",
      "  -2.06944935e-03 -1.85029150e-02 -2.18228342e-02 -6.01888006e-03\n",
      "   3.09165585e-03  4.07736699e-03 -1.43380079e-02 -1.39624255e-03\n",
      "   1.41022731e-03  1.09682131e-04 -1.20158802e-02 -4.99305684e-03\n",
      "  -4.45389190e-04 -5.91410364e-02 -6.72722919e-03 -1.40364317e-02\n",
      "  -1.39579858e-02 -1.58444336e-02 -1.18901930e-03 -9.09626524e-03\n",
      "   3.34773904e-06 -4.51975906e-03  5.68693712e-03  5.68693712e-03\n",
      "   5.68693712e-03  5.68693712e-03  5.68693712e-03  5.68693712e-03\n",
      "   5.68693712e-03  5.68693712e-03  5.68693712e-03  5.68693712e-03\n",
      "   5.68693712e-03  5.68693712e-03  5.68693712e-03  5.68693712e-03\n",
      "   5.68693712e-03  5.68693712e-03  5.68693712e-03  5.68693712e-03\n",
      "   5.68693712e-03  5.68693712e-03  5.68693712e-03  5.68693712e-03\n",
      "   5.68693712e-03  5.68693712e-03  5.68693712e-03  5.68693712e-03\n",
      "   5.68693712e-03  5.68693712e-03  5.68693712e-03  5.68693712e-03\n",
      "   5.68693712e-03  5.68693712e-03  5.68693712e-03  5.68693712e-03\n",
      "   5.68693712e-03  5.68693712e-03  5.68693712e-03  5.68693712e-03\n",
      "   5.68693712e-03  5.68693712e-03  5.68693712e-03  5.68693712e-03\n",
      "   5.68693712e-03  5.68693712e-03  5.68693712e-03  5.68693712e-03\n",
      "   5.68693712e-03  5.68693712e-03  5.68693712e-03  5.68693712e-03]]\n",
      "cost after 700 iteration: [[-7.47596762e-04 -1.08603441e-02 -4.18163478e-03 -1.52701156e-02\n",
      "  -3.12734068e-05 -2.02538384e-03 -4.99634926e-03 -4.59209634e-03\n",
      "  -1.94065501e-02 -1.04597844e-02  4.56784466e-04 -9.01425338e-03\n",
      "  -9.75426449e-03 -3.17572786e-03  4.03773302e-03  3.58845570e-03\n",
      "   2.68701798e-03 -1.49221098e-03 -1.43422858e-03  4.05836344e-05\n",
      "  -8.75495107e-03 -1.72508295e-03  2.97548973e-03 -2.26204635e-02\n",
      "  -2.73554794e-02 -2.13725117e-02 -1.11943312e-02 -2.23097864e-03\n",
      "  -1.56680799e-03 -1.62376836e-02 -1.92613079e-02 -5.03561548e-03\n",
      "   2.84880459e-03  3.66522919e-03 -1.24649624e-02 -9.81825402e-04\n",
      "   1.43038035e-03  3.18472193e-04 -1.03757795e-02 -4.12680756e-03\n",
      "  -1.61266850e-04 -5.40190163e-02 -5.65881126e-03 -1.22100449e-02\n",
      "  -1.21335599e-02 -1.38294100e-02 -8.03461622e-04 -7.76392946e-03\n",
      "   2.26169294e-04 -3.71017555e-03  4.93969208e-03  4.93969208e-03\n",
      "   4.93969208e-03  4.93969208e-03  4.93969208e-03  4.93969208e-03\n",
      "   4.93969208e-03  4.93969208e-03  4.93969208e-03  4.93969208e-03\n",
      "   4.93969208e-03  4.93969208e-03  4.93969208e-03  4.93969208e-03\n",
      "   4.93969208e-03  4.93969208e-03  4.93969208e-03  4.93969208e-03\n",
      "   4.93969208e-03  4.93969208e-03  4.93969208e-03  4.93969208e-03\n",
      "   4.93969208e-03  4.93969208e-03  4.93969208e-03  4.93969208e-03\n",
      "   4.93969208e-03  4.93969208e-03  4.93969208e-03  4.93969208e-03\n",
      "   4.93969208e-03  4.93969208e-03  4.93969208e-03  4.93969208e-03\n",
      "   4.93969208e-03  4.93969208e-03  4.93969208e-03  4.93969208e-03\n",
      "   4.93969208e-03  4.93969208e-03  4.93969208e-03  4.93969208e-03\n",
      "   4.93969208e-03  4.93969208e-03  4.93969208e-03  4.93969208e-03\n",
      "   4.93969208e-03  4.93969208e-03  4.93969208e-03  4.93969208e-03]]\n",
      "cost after 800 iteration: [[-4.89166375e-04 -9.57182507e-03 -3.54019739e-03 -1.36047923e-02\n",
      "   1.40780368e-04 -1.62235348e-03 -4.27256651e-03 -3.90805398e-03\n",
      "  -1.74122008e-02 -9.20510065e-03  5.68554325e-04 -7.89623197e-03\n",
      "  -8.56350471e-03 -2.64023011e-03  3.64457868e-03  3.26737994e-03\n",
      "   2.50070775e-03 -1.14794500e-03 -1.09690267e-03  2.02751996e-04\n",
      "  -7.66037149e-03 -1.35573806e-03  2.74806775e-03 -2.04026093e-02\n",
      "  -2.47925230e-02 -1.92293688e-02 -9.88360165e-03 -1.80169050e-03\n",
      "  -1.21261208e-03 -1.44940621e-02 -1.72788045e-02 -4.30880083e-03\n",
      "   2.64004404e-03  3.33255339e-03 -1.10357014e-02 -6.95260262e-04\n",
      "   1.41758911e-03  4.48192403e-04 -9.13155514e-03 -3.49140780e-03\n",
      "   2.59217818e-05 -4.99186121e-02 -4.86534775e-03 -1.08169752e-02\n",
      "  -1.07426633e-02 -1.22863290e-02 -5.38969126e-04 -6.76328635e-03\n",
      "   3.66563665e-04 -3.11878184e-03  4.37318912e-03  4.37318912e-03\n",
      "   4.37318912e-03  4.37318912e-03  4.37318912e-03  4.37318912e-03\n",
      "   4.37318912e-03  4.37318912e-03  4.37318912e-03  4.37318912e-03\n",
      "   4.37318912e-03  4.37318912e-03  4.37318912e-03  4.37318912e-03\n",
      "   4.37318912e-03  4.37318912e-03  4.37318912e-03  4.37318912e-03\n",
      "   4.37318912e-03  4.37318912e-03  4.37318912e-03  4.37318912e-03\n",
      "   4.37318912e-03  4.37318912e-03  4.37318912e-03  4.37318912e-03\n",
      "   4.37318912e-03  4.37318912e-03  4.37318912e-03  4.37318912e-03\n",
      "   4.37318912e-03  4.37318912e-03  4.37318912e-03  4.37318912e-03\n",
      "   4.37318912e-03  4.37318912e-03  4.37318912e-03  4.37318912e-03\n",
      "   4.37318912e-03  4.37318912e-03  4.37318912e-03  4.37318912e-03\n",
      "   4.37318912e-03  4.37318912e-03  4.37318912e-03  4.37318912e-03\n",
      "   4.37318912e-03  4.37318912e-03  4.37318912e-03  4.37318912e-03]]\n",
      "cost after 900 iteration: [[-0.00030506 -0.00855894 -0.00305112 -0.01228269  0.00025684 -0.0013235\n",
      "  -0.00371719 -0.00338485 -0.01581804 -0.00822002  0.00063723 -0.00702222\n",
      "  -0.0076305  -0.00223599  0.00332499  0.00300202  0.00233807 -0.00089582\n",
      "  -0.00085036  0.00031111 -0.00680563 -0.0010836   0.00255389 -0.01862236\n",
      "  -0.0227246  -0.01751204 -0.00885221 -0.00148216 -0.00095273 -0.01310747\n",
      "  -0.01569471 -0.00375107  0.00246009  0.00305838 -0.00990769 -0.00048892\n",
      "   0.00138896  0.00053093 -0.00815462 -0.00300725  0.00015396 -0.04654467\n",
      "  -0.00425398 -0.00971783 -0.00964571 -0.01106469 -0.00035005 -0.00598452\n",
      "   0.00045771 -0.00266986  0.00392831  0.00392831  0.00392831  0.00392831\n",
      "   0.00392831  0.00392831  0.00392831  0.00392831  0.00392831  0.00392831\n",
      "   0.00392831  0.00392831  0.00392831  0.00392831  0.00392831  0.00392831\n",
      "   0.00392831  0.00392831  0.00392831  0.00392831  0.00392831  0.00392831\n",
      "   0.00392831  0.00392831  0.00392831  0.00392831  0.00392831  0.00392831\n",
      "   0.00392831  0.00392831  0.00392831  0.00392831  0.00392831  0.00392831\n",
      "   0.00392831  0.00392831  0.00392831  0.00392831  0.00392831  0.00392831\n",
      "   0.00392831  0.00392831  0.00392831  0.00392831  0.00392831  0.00392831\n",
      "   0.00392831  0.00392831  0.00392831  0.00392831]]\n"
     ]
    }
   ],
   "source": [
    "param = model(X_data, Y, 1000, 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
